# Kafka 내부 동작 이해하기 3 - 컨트롤러와 로그 세그먼트 (Controller, Log Segment)
### 컨트롤러
* 리더 파티션에 장애가 발생하면 팔로워 중에서 새로운 리더를 승격시켜야 하는데, 승격해주는 주체가 바로 **컨트롤러**이다.
* **카프카 클러스터 중 하나의 브로커**가 컨트롤러의 역할을 한다.
* **ISR**(InSyncReplica) 리스트에서 리더를 선출하며, ISR 리스트는 **가용성 보장**을 위해 **주키퍼**에 저장되어 있다.
* 리더 승격 과정은 빠르게 진행되어야 하는데, 그 이유는 **파티션의 리더가 다운되어 새로운 리더를 선택하지 못하는 상황이 지연되면 모든 읽기/쓰기 동작이 실패**될 것이기 때문

![kafka-leader-controller](https://github.com/user-attachments/assets/68cd36ad-f8fd-472b-9f81-61eb5bf78971)

1. 0번 파티션의 리더가 있는 브로커 1번이 다운
2. 주키퍼는 0번 파티션에서 변화가 생겼음을 감지
3. 컨트롤러는 주키퍼의 감지를 통해 0번 파티션에 변화가 생겼음을 인지, 해당 ISR 중 하나의 팔로워를 새로운 리더로 승격
4. 컨트롤러는 0번 파티션의 새로운 리더 정보를 주키퍼에 기록
5. 갱신된 정보를 모든 브로커에게 전파
<br/>

* 카프카 초기에는 이러한 과정에서 많은 시간이 발생했다.
* 이를 개선하기 위해 카프카 버전 1.1에서는 **불필요한 로깅 작업을 없애고 주키퍼 비동기 API를 반영**하면서 해결했다.

### 로그 (로그 세그먼트)
* 카프카의 토픽으로 들어오는 메시지 (레코드)는 **세그먼트라는 파일**에 저장된다.
* 메시지는 정해진 형식에 맞추어 메시지의 내용, 키, 값, 오프셋, 크기 같은 정보가 함께 저장되며 **브로커의 로컬 디스크에 보관**된다.
* 로그 세그먼트 파일 크기가 너무 커지면 관리가 어렵기 떄문에 최대 크기는 **1GB**로 디폴트 설정되어 있다.
  * 로그 세그먼트가 1GB를 넘기게 되면 해당 파일을 Close하고 새로운 세그먼트를 생성한다. (**롤링 전략**)
  * 하지만 1GB 로그 세그먼트가 무한히 늘어날 경우 이 또한 문제이므로 이를 어떻게 관리할 것인가도 중요하다.

### 로그 세그먼트 컴팩션
* 브로커의 로컬 디스크에 저장되어 있는 세그먼트를 대상으로, 현재 활성화된 세그먼트는 제외하고 나머지 세그먼트들을 대상으로 컴팩션 실행
  * 메시지(레코드) **키 값을 기준으로 마지막의 데이터만 보관**
* 로그 컴팩션 기능을 사용하는 대표적인 예: **__consumer_offset 토픽**
  * 카프카의 내부 토픽으로, 컨슈머 그룹의 정보를 저장하는 토픽
  * 오프셋 커밋 정보가 **__consumer_offset 토픽의 키** (컨슈머 그룹명, 토픽명)와 **값** (오프셋 커밋 정보) 형태로 저장
    * 만약 위와 같은 작업이 3번 진행된다고 하면 토픽에 저장된 메시지는 총 3개일 것
    * 이후 로그 컴팩션 동작이 일어나면 해당 메시지의 키 값의 메시지는 마지막 데이터 3번만 남게 된다.
    * 즉 마지막으로 커밋된 오프셋 정보가 중요하므로, 그 이전 정보들은 삭제해도 무방하다는 것

* **컴팩션 전 로그**

|오프셋|0|1|2|3|4|5|6|7|8|
|---|---|---|---|---|---|---|---|---|---|
|키|k1|k2|k2|k1|k3|k2|k2|k3|k3|
|값|v1|v2|v3|v4|v5|v6|v7|v8|v9|

* **컴팩션 후 로그**

|오프셋|3|6|8|
|---|---|---|---|
|키|k1|k2|k3|
|값|v4|v7|v9|

* 하지만 **모든 토픽에 대해 로그 컴팩션을 수행하는 것은 좋지 않다.**
  * 컴팩션 작업이 수행되면 **브로커의 과도한 입출력 부하**가 발생할 수 있다.
  * 브로커의 리소스 모니터링도 병행하면서 로그 컴팩션을 사용해야 한다.


